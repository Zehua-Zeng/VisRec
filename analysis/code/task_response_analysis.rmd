---
title: "task_response_analysis"
output: html_document
---

```{r libraries, message=FALSE, warning=FALSE}

knitr::opts_chunk$set(fig.align="center") 
library(rstanarm)
library(tidyverse)
library(tidybayes)
library(modelr) 
library(ggplot2)
library(magrittr)  
library(emmeans)
library(bayesplot)
library(brms)
library(gganimate)

theme_set(theme_light())

```


###Read in data

```{r data_prep}

time_data = read.csv('processed_completion_time.csv')
accuracy_data = read.csv('processed_accuracy_split.csv')

analyses = c("confidence.udata", "confidence.ans", "efficiency", "ease.of.use", "utility", "overall")
confidence_metrics = c("confidence.udata", "confidence.ans")
preference_metrics = c("efficiency", "ease.of.use", "utility", "overall")
seed = 12
```

```{r task_response_ordinal}
analyses = c("confidence.udata", "confidence.ans", "efficiency", "ease.of.use", "utility", "overall")
confidence_metrics = c("confidence.udata", "confidence.ans")
preference_metrics = c("efficiency", "ease.of.use", "utility", "overall")

differences = c("search", "oracle", "alg")
seed = 12

data <- read.csv('processed_ptask_responses.csv')
data[,analyses] <- lapply(data[,analyses],ordered)
data <- data %>%
  mutate(
    dataset = as.factor(dataset),
    oracle = as.factor(oracle),
    search = as.factor(search),
    task = as.factor(task)
  )

generate_model_and_draws = function(data, attr, generate_eval_plots = FALSE) {
  filename = gsub("\\.", "_", attr)
  data$y = data[,attr]
  model <- brm(
    formula = bf(y ~ dataset * oracle * search * task_type),
    family = cumulative("probit"),
    prior = prior(normal(0, 1), class = b),
    chains = 2,
    cores = 2,
    iter = 2500,
    warmup = 1000,
    data = data,
    control = list(adapt_delta = 0.99),
    file = filename,
    seed = seed
  )
  if(generate_eval_plots){
    # check that Rhat is close to 1, Bult_ESS is in the thousands
    summary(model)
    plot(model)
  
  pairs(
    model,
    pars = c(
      "b_Intercept[1]",
      "b_Intercept[2]",
      "b_Intercept[3]"
    ),
    fixed = TRUE
  )
  
  pairs(
    model,
    pars = c(
      "b_datasetmovies",
      "b_oracledziban",
      "b_searchdfs",
      "b_task_typeOpenMEnded"
    ),
    fixed = TRUE
  )
  
  data %>%
    mutate(rating = y) %>%
    ggplot(aes(x = oracle, fill = rating)) +
    geom_bar() +
    theme_minimal() +
    facet_grid(. ~ search)
  
  data %>%
    add_predicted_draws(model, seed = seed) %>%
    group_by(search, oracle, dataset) %>%
    summarize(rating = .prediction) %>%
    ggplot(aes(x = oracle, fill = rating)) +
    geom_bar() +
    theme_minimal() +
    facet_grid(. ~ search)
  
  spec <- data %>%
    add_predicted_draws(model, seed = seed, n = 50) %>%
    mutate(rating = .prediction) %>%
    ggplot(aes(x = oracle, fill = rating)) +
    geom_bar() +
    theme_minimal() +
    facet_grid(. ~ search) +
    transition_manual(.draw)
  
    animate(spec, fps = 2.5)
    
    spec2 <- data %>%
  add_predicted_draws(model, seed = 14, n = 50) %>%
    mutate(
      observed = ordered(y, levels=c("-2","-1", "0", "1", "2")),
      predicted = ordered(.prediction, levels=c("-2",-"1", "0", "1", "2"))) %>%
    pivot_longer(cols = c("observed", "predicted"), names_to = "source", values_to = "rating") %>%
    ggplot(aes(x = rating, fill = source)) +
      geom_bar(position = position_dodge()) +
      theme_minimal() +
      facet_wrap(. ~ participant_id) +
      transition_manual(.draw)
    
  animate(spec2, fps = 2.5)
  }
  
  predictive_plot_data <- data %>%
    add_predicted_draws(model, seed = seed, re_formula = NA) %>%
    group_by(search, oracle, .draw) %>%
    mutate(rating = weighted.mean(as.numeric(as.character(.prediction))))
  
  predictive_plot <- predictive_plot_data %>%
    ggplot(aes(x = oracle, y = rating)) +
    stat_eye(.width = c(.95, .5)) +
    theme_minimal() +
    coord_cartesian(ylim = c(-2, 2)) +
    facet_grid(. ~ search)
  
  ggsave(file=paste(filename, ".png", sep=""), plot=predictive_plot, path = "../plots/posterior_draws/user_response", width = 7, height = 7)
  credible_intervals <- predictive_plot_data %>% group_by(search, oracle) %>% mean_qi(rating, .width = c(.95, .5))
  write.csv(credible_intervals, paste("../plot_data/posterior_draws/user_response/",filename,".csv", sep=""), row.names = FALSE, append=FALSE)
  
  predictive_plot_focused_open_split <- predictive_plot_data %>%
    ggplot(aes(x = oracle, y = rating, fill=search, alpha = 0.5)) +
    stat_eye(.width = c(.95, .5)) +
    theme_minimal() +
    coord_cartesian(ylim = c(-2, 2)) +
    facet_grid(. ~ task_type)
  
  ggsave(file=paste(filename, "_focused_open_split.png", sep=""), plot=predictive_plot_focused_open_split, path = "../plots/posterior_draws/user_response", width = 7, height = 7)
  credible_intervals <- predictive_plot_data %>% group_by(search, oracle, task_type) %>% mean_qi(rating, .width = c(.95, .5))
  write.csv(credible_intervals, paste("../plot_data/posterior_draws/user_response/",filename,"_focused_open_split.csv", sep=""), row.names = FALSE, append=FALSE)
  
  return(model)
}
draw_data_combined <- list()
differences_intervals <- list()

for (diff in differences){
  draw_data_combined[[diff]] <- data.frame()
  differences_intervals[[diff]] <- data.frame()
}

get_differences_and_intervals = function(draws, variable_to_compare, metric){
  difference_data <- draw_data %>%
    group_by(!!sym(variable_to_compare), .draw) %>%
    summarize(rating = weighted.mean(as.numeric(.prediction))) %>%
    compare_levels(rating, by = !!sym(variable_to_compare)) %>%
    rename(diff_in_rating = rating) 
  
  difference_data['metric'] = metric
  difference_credible_intervals <- difference_data %>% mean_qi(diff_in_rating, .width = c(.95, .5))
  difference_credible_intervals['metric'] = metric
  
  return(list("differences" = difference_data, "intervals" = difference_credible_intervals))
}

for (attr in analyses) {
  model = generate_model_and_draws(data, attr)
  draw_data <- data %>%
  add_predicted_draws(model, seed = seed, re_formula = NA) 
  
  draw_data$alg <- paste(draw_data$search, draw_data$oracle)
  
  for (diff in differences){
    vals <- get_differences_and_intervals(draw_data, diff, attr)
    draw_data_combined[[diff]] <- rbind(draw_data_combined[[diff]], vals$differences)
    differences_intervals[[diff]] <- rbind(differences_intervals[[diff]], vals$intervals)
  }
}

# flip order so that we get bfs - dfs
if(draw_data_combined$search[1,'search']=="dfs - bfs"){
  draw_data_combined$search$search = 'bfs - dfs'
  draw_data_combined$search$diff_in_rating = -1 * draw_data_combined$search$diff_in_rating
}

if(differences_intervals$search[1,'search']=="dfs - bfs"){
  differences_intervals$search$search = 'bfs - dfs'
  differences_intervals$search$temp = -1 * differences_intervals$search$.lower
  differences_intervals$search$diff_in_rating = -1 * differences_intervals$search$diff_in_rating
  differences_intervals$search$lower = -1 * differences_intervals$search$.upper
  differences_intervals$search$.upper = differences_intervals$search$temp 
}

generate_difference_plot = function(data, xLab, yLab, filename){
   difference_plot <- data %>%
      ggplot(aes(x = diff_in_rating, y = metric)) +
      ylab(yLab) +
      xlab(xLab) +
      stat_halfeye(.width = c(.95, .5)) +
      geom_vline(xintercept = 0, linetype = "longdash") +
      theme_minimal()
    ggsave(file=filename, plot=difference_plot, path = "../plots/comparisons/user_response", width = 7, height = 7)
}

generate_confidence_and_preference_plots = function(data, variable_to_compare){
  data$metric <- factor(data$metric, levels=rev(analyses))
  
  generate_difference_plot(subset(data, metric %in% confidence_metrics),
                            paste0("Expected Difference in Rating (",data[1,variable_to_compare],")"),
                            "Confidence",
                           paste0(variable_to_compare, "_rating_differences_confidence.png")
                            )
  
  generate_difference_plot(subset(data, metric %in% preference_metrics),
                            paste0("Expected Difference in Rating (",data[1,variable_to_compare],")"),
                            "Preference",
                           paste0(variable_to_compare, "_rating_differences_preference.png")
                            )
}

for (diff in differences){
  subsetted_draw_data <- data.frame()
  if(diff=="alg"){
    subsetted_draw_data <- subset(draw_data_combined[[diff]], alg == "dfs compassql - bfs dziban")
    }
  else {
    subsetted_draw_data <- draw_data_combined[[diff]]
  }
  
  generate_confidence_and_preference_plots(subsetted_draw_data, diff)
  write.csv(differences_intervals[[diff]], paste0("../plot_data/comparisons/user_response/",diff, "_rating_differences.csv"), row.names = FALSE)
}

```

```{r time_analysis}  
# analysis to predict time elapsed for the user to complete a certain task given a dataset, oracle, and search algorithm
time_data = read.csv('processed_completion_time.csv')
analyses = c(
  "confidence.udata",
  "confidence.ans",
  "efficiency",
  "ease.of.use",
  "utility",
  "overall"
)
confidence_metrics = c("confidence.udata", "confidence.ans")
preference_metrics = c("efficiency", "ease.of.use", "utility", "overall")
seed = 12

time_data <- time_data %>%
  mutate(
    dataset = as.factor(dataset),
    oracle = as.factor(oracle),
    search = as.factor(search)
  )

prior_mean = 5.69
prior_sd = 0.69
# priors for completion time of each task were derived from a pilot study
task_list = c("1. Find Extremum",
              "2. Retrieve Value",
              "3. Prediction",
              "4. Exploration")
alg_difference_draws <- data.frame()
alg_difference_intervals <- data.frame()

search_difference_draws <- data.frame()
search_difference_intervals <- data.frame()

oracle_difference_draws <- data.frame()
oracle_difference_intervals <- data.frame()

get_differences_and_intervals = function(draws, variable_to_compare, metric){
  difference_data <- draw_data %>%
    group_by(!!sym(variable_to_compare), dataset, .draw) %>%
    summarize(time = weighted.mean(exp(.value))) %>%
    compare_levels(time, by = !!sym(variable_to_compare)) %>%
    rename(diff_in_time = time) 
  
  difference_data['metric'] = metric
  difference_credible_intervals <- difference_data %>% mean_qi(diff_in_time, .width = c(.95, .5))
  difference_credible_intervals['metric'] = metric
  
  return(list("differences" = difference_data, "intervals" = difference_credible_intervals))
}
all_draws = data.frame()

run_model_time = function(data, task, a_prior, a_sd) {
  data$y = log(data$completion_time)
  
  # train model
  model = stan_glm(
    y ~ dataset * oracle * search,
    data = data,
    prior_intercept = normal(a_prior, a_sd, autoscale = FALSE),
    prior = normal(0, a_sd, autoscale = FALSE),
    seed = seed
  )
  return(model)
}

for (task_name in task_list) {
  print(task_name)
  data_sub <- subset(time_data, task == task_name)
  print(data_sub)
  model <- run_model_time(data_sub, task_name, prior_mean, prior_sd)
  
  draw_data <- data %>%
  add_fitted_draws(model, seed = seed, re_formula = NA)
  draw_data$task <- task_name
  all_draws <- rbind(all_draws, draw_data)
  
  fit_info =  draw_data %>% mean_qi(exp(.value), .width = c(.95, .5))
  
  plot = ggplot(draw_data, aes(
    x = exp(.value),
    y = condition,
    fill = dataset,
    alpha = 0.5
  )) + stat_halfeye(.width = c(.95, .5)) +
    labs(x = "Time (Seconds)", y = "Condition") 
  
  filename = gsub("^.*\\.","", task_name )
  filename = gsub(" ", "_", filename)
  filename = paste("time", filename, sep = "")
  
  ggsave(
    file = paste(filename, ".png", sep = ""),
    plot = plot,
    path = "../plots/posterior_draws/time"
  )
  write.csv(fit_info,
            paste("../plot_data/posterior_draws/time/", filename, ".csv", sep = ""),
            row.names = FALSE)
  
  draw_data <- data %>%
  add_fitted_draws(model, seed = seed, re_formula = NA)
  draw_data$alg <- paste(draw_data$search, draw_data$oracle, sep= " ")

  search_vals <- get_differences_and_intervals(draw_data, "search", task_name)
  search_difference_draws <- rbind(search_difference_draws, search_vals$differences)
  search_difference_intervals <- rbind(search_difference_intervals, search_vals$intervals)

  oracle_vals <- get_differences_and_intervals(draw_data, "oracle", task_name)
  oracle_difference_draws <- rbind(oracle_difference_draws, oracle_vals$differences)
  oracle_difference_intervals <- rbind(oracle_difference_intervals, oracle_vals$intervals)

  alg_vals <- get_differences_and_intervals(draw_data, "alg", task_name)
  alg_difference_draws <- rbind(alg_difference_draws, alg_vals$differences)
  alg_difference_intervals <- rbind(alg_difference_intervals, alg_vals$intervals)
  
}

generate_difference_plot = function(data, xLab, yLab, filename){
   difference_plot <- data %>%
      ggplot(aes(x = diff_in_time, y = metric)) +
      ylab(yLab) +
      xlab(xLab) +
      stat_halfeye(.width = c(.95, .5)) +
      geom_vline(xintercept = 0, linetype = "longdash") +
      theme_minimal()
    ggsave(file=filename, plot=difference_plot, path = "../plots/comparisons/time", width = 7, height = 7)
    
    difference_plot_split_by_dataset <- data %>%
      ggplot(aes(x = diff_in_time, y = metric)) +
      facet_grid(. ~ dataset) +
      ylab(yLab) +
      xlab(xLab) +
      stat_halfeye(.width = c(.95, .5)) +
      geom_vline(xintercept = 0, linetype = "longdash") +
      theme_minimal()
    ggsave(file=paste0("split_by_dataset_",filename), plot=difference_plot_split_by_dataset, path = "../plots/comparisons/time", width = 7, height = 7)

}
search_difference_draws$metric <- factor(search_difference_draws$metric, levels=rev(task_list))
oracle_difference_draws$metric <- factor(oracle_difference_draws$metric, levels=rev(task_list))
alg_difference_draws$metric <- factor(alg_difference_draws$metric, levels=rev(task_list))
generate_difference_plot(search_difference_draws, paste0("Time Difference (Seconds): ", search_difference_draws[1,'search']), "Task", "search_time_differences.png")
generate_difference_plot(oracle_difference_draws, paste0("Time Difference (Seconds): ", oracle_difference_draws[1,'oracle']),  "Task", "oracle_time_differences.png")
generate_difference_plot(alg_difference_draws, paste0("Time Difference (Seconds): ", alg_difference_draws[1,'alg']),  "Task", "alg_time_differences.png")
write.csv(search_difference_intervals, paste("../plot_data/comparisons/time/search_time_differences.csv", sep=""), row.names = FALSE)
write.csv(oracle_difference_intervals, paste("../plot_data/comparisons/time/oracle_time_differences.csv", sep=""), row.names = FALSE)
write.csv(alg_difference_intervals, paste("../plot_data/comparisons/time/alg_time_differences.csv", sep=""), row.names = FALSE)

 plot = ggplot(all_draws, aes(
    x = exp(.value),
    y = task,
    fill = search,
    alpha = 0.5
  )) + stat_halfeye(.width = c(.95, .5)) +
    labs(x = "Time (Seconds)", y = "Task") +  facet_grid(. ~ dataset)

 ggsave(
    file = paste("all_tasks_search.png", sep = ""),
    plot = plot,
    path = "../plots/posterior_draws/time"
  )
```

```{r time_analysis_focused_or_open}  
# The different tasks can be decribed as "focused" or "open-ended", so let's run analyses where we split on that attribute
run_model_time(subset(time_data, task_type == "Focused"), "Focused", prior_mean, prior_sd, TRUE)
run_model_time(subset(time_data, task_type == "Open-Ended"), "Open-Ended", prior_mean, prior_sd, TRUE)
```

```{r misc_analyses}
run_model_time(subset(time_data, task == "3. Prediction"), "Prediction (split by dataset)", 870.53, 657.68, TRUE)
run_model_time(subset(time_data, task == "1. Find Extremum"), "Find Extremum (split by dataset)", 190.34, 96.57, TRUE)
```

```{r accuracy_analysis}

accuracy_data = read.csv('processed_accuracy_split.csv')

analyses = c("confidence.udata", "confidence.ans", "efficiency", "ease.of.use", "utility", "overall")
confidence_metrics = c("confidence.udata", "confidence.ans")
preference_metrics = c("efficiency", "ease.of.use", "utility", "overall")
seed = 12

accuracy_data = read.csv('processed_accuracy_split.csv')
accuracy_tasks = c("1. Find Extremum", "2. Retrieve Value")
accuracy_data$oracle = as.factor(accuracy_data$oracle)
accuracy_data$search = as.factor(accuracy_data$search)
accuracy_data$dataset = as.factor(accuracy_data$dataset)
accuracy_data = subset(accuracy_data, task == "1. Find Extremum")

generate_accuracy_model_and_draws = function(data){
  
}
model_binary <- brm(accuracy ~ oracle*search+dataset, 
                    data = accuracy_data,
                    prior = c(prior(normal(1, .05), class = Intercept)),
                    family = bernoulli(link = "logit"),
                    warmup = 500, 
                    iter = 3000, 
                    chains = 2, 
                    cores=2,
                    seed=seed
                    )

# START evaluation
accuracy_data %>%
  select(-accuracy) %>%
  add_predicted_draws(model_binary, prediction = "accuracy", seed = seed) %>%
  ggplot(aes(x = accuracy)) +
  geom_density(fill = "black", size = 0) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Prior predictive distribution for correctness") +
  theme(panel.grid = element_blank())

stanplot(model_binary, type="trace")
stanplot(model_binary, type="acf_bar")
summary(model_binary)
stanplot(model_binary, type="areas", prob=0.95)
exp(fixef(model_binary)[,-2])

plot(model_binary)
pairs(model_binary)

accuracy_data %>%
    add_fitted_draws(model_binary, seed = seed, re_formula = NA) %>%
    group_by(search, oracle, dataset, .draw) %>%
    ggplot(aes(x = oracle, y = .value)) +
    stat_eye(.width = c(.95, .5)) +
    theme_minimal() +
    coord_cartesian(ylim = c(0, 1)) +
    facet_grid(. ~ search)


pred <- predict(model_binary, type = "response")
pred <- if_else(pred[,1] > 0.5, 1, 0)
confusion_matrix <- table(pred, pull(accuracy_data, accuracy)) 

# END evalutation

```






